{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch blitz tutorial "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor tutorial "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch is based around GPU-powered tensors, which are the same notion as numpy ndarrays. Let's see some of the basic functionalities of tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T22:53:41.414862Z",
     "start_time": "2020-05-18T22:53:41.062796Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torch works very much like numpy, but it leverages the power of GPUs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T22:54:17.093267Z",
     "start_time": "2020-05-18T22:54:17.078991Z"
    }
   },
   "outputs": [],
   "source": [
    "# initialize an empty array \n",
    "\n",
    "x = torch.empty(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T22:54:19.694534Z",
     "start_time": "2020-05-18T22:54:19.677188Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.5873e-43, 3.6013e-43, 3.5873e-43, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 1.1704e-41, 0.0000e+00, 2.2369e+08],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T22:55:07.757877Z",
     "start_time": "2020-05-18T22:55:07.750114Z"
    }
   },
   "outputs": [],
   "source": [
    "# initialize a random matrix, each entry is drawn from a Unif(0,1)\n",
    "rand_mat = torch.rand(5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T22:55:09.941589Z",
     "start_time": "2020-05-18T22:55:09.932405Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3533, 0.2380],\n",
       "        [0.7897, 0.1315],\n",
       "        [0.6030, 0.4055],\n",
       "        [0.1396, 0.2026],\n",
       "        [0.3203, 0.3006]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T22:55:21.462205Z",
     "start_time": "2020-05-18T22:55:21.454150Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.long?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T22:56:36.733792Z",
     "start_time": "2020-05-18T22:56:36.717518Z"
    }
   },
   "outputs": [],
   "source": [
    "# iitialize a zeros matrix with 64bit integer\n",
    "zero_mat = torch.zeros(5,2, dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T22:56:43.175993Z",
     "start_time": "2020-05-18T22:56:43.166315Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A single sliced element is still a tensor ! \n",
    "type(zero_mat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T22:56:57.436559Z",
     "start_time": "2020-05-18T22:56:57.409213Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T22:57:03.020719Z",
     "start_time": "2020-05-18T22:57:03.008697Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_mat.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also construct a custom tensor just as in numpy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T22:58:05.125133Z",
     "start_time": "2020-05-18T22:58:05.114689Z"
    }
   },
   "outputs": [],
   "source": [
    "# initalize a tensor \n",
    "\n",
    "tensr = torch.tensor([4, 1.318])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T22:58:06.843549Z",
     "start_time": "2020-05-18T22:58:06.834532Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.0000, 1.3180])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other methods, like reusing an input tensor in the analog of `np.zeros_like` or `np.ones_like`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T23:00:41.867461Z",
     "start_time": "2020-05-18T23:00:41.841126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(5,3, dtype = torch.double)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T23:01:08.660512Z",
     "start_time": "2020-05-18T23:01:08.647546Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0749,  1.5335,  1.5302],\n",
      "        [-0.3629, -0.0477, -0.0702],\n",
      "        [ 0.2095, -0.1990, -0.5140],\n",
      "        [-0.8874,  0.7084, -1.5200],\n",
      "        [ 0.7630, -0.9652,  0.1887]])\n"
     ]
    }
   ],
   "source": [
    "# initializes a tensor with shape of input tensor, \n",
    "# entries drawn from a std. normal distribution\n",
    "x = torch.randn_like(x, dtype = torch.float)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple syntaxes for operations. These are the analog of numpy having multiple operations for matrix multiplication `np.dot(x,y)`, `np.matmul(x,y)` or `x @ y`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T23:04:17.032931Z",
     "start_time": "2020-05-18T23:04:17.022038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1386,  1.9243,  2.4603],\n",
      "        [ 0.2110, -0.0361,  0.0612],\n",
      "        [ 0.2895, -0.0624, -0.4269],\n",
      "        [ 0.0999,  1.0217, -1.0218],\n",
      "        [ 0.9273, -0.8630,  0.2767]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5,3)\n",
    "\n",
    "# syntax 1\n",
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T23:04:34.154716Z",
     "start_time": "2020-05-18T23:04:34.143068Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1386,  1.9243,  2.4603],\n",
       "        [ 0.2110, -0.0361,  0.0612],\n",
       "        [ 0.2895, -0.0624, -0.4269],\n",
       "        [ 0.0999,  1.0217, -1.0218],\n",
       "        [ 0.9273, -0.8630,  0.2767]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# syntax 2 \n",
    "\n",
    "torch.add(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T23:05:15.994050Z",
     "start_time": "2020-05-18T23:05:15.984987Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1386,  1.9243,  2.4603],\n",
       "        [ 0.2110, -0.0361,  0.0612],\n",
       "        [ 0.2895, -0.0624, -0.4269],\n",
       "        [ 0.0999,  1.0217, -1.0218],\n",
       "        [ 0.9273, -0.8630,  0.2767]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Syntax 3: addition in-place \n",
    "y.add_(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also index torch tensors, numpy-style ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T23:06:39.602137Z",
     "start_time": "2020-05-18T23:06:39.592670Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0749,  1.5335,  1.5302],\n",
       "        [-0.3629, -0.0477, -0.0702],\n",
       "        [ 0.2095, -0.1990, -0.5140],\n",
       "        [-0.8874,  0.7084, -1.5200],\n",
       "        [ 0.7630, -0.9652,  0.1887]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T23:06:28.172704Z",
     "start_time": "2020-05-18T23:06:28.162291Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.5302, -0.0702, -0.5140, -1.5200,  0.1887])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `torch.view` for reshaping a tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T23:07:50.783762Z",
     "start_time": "2020-05-18T23:07:50.772598Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.randn(4,4)\n",
    "\n",
    "y = x.view(16)\n",
    "\n",
    "z = x.view(-1, 8) # the size -1 is inferred from other dimensions \n",
    "\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have a one element tensor, use `.item()` to get the values as a python number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T23:09:35.235906Z",
     "start_time": "2020-05-18T23:09:35.227172Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3037])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "\n",
    "# Returns tensor\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T23:09:47.764547Z",
     "start_time": "2020-05-18T23:09:47.753652Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3037445545196533"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T23:10:45.616372Z",
     "start_time": "2020-05-18T23:10:45.610883Z"
    }
   },
   "source": [
    "Torch has more than 100 tensor operations like random numbers (see `torch.randperm`), striding tricks, signal processing(`torch.stft`), linear algebra (`torch.det`, `torch.lu`, `torch.lstsq`), etc. [read the docs !](https://pytorch.org/docs/stable/torch.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T23:15:51.394944Z",
     "start_time": "2020-05-18T23:15:51.389429Z"
    }
   },
   "source": [
    "### Bridging torch and numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T23:21:24.100290Z",
     "start_time": "2020-05-18T23:21:24.090329Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize torch array \n",
    "a = torch.ones(5)\n",
    "\n",
    "b = a.numpy()\n",
    "\n",
    "type(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T23:21:45.410778Z",
     "start_time": "2020-05-18T23:21:45.397996Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.from_numpy(b)\n",
    "\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA tensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T23:22:16.930795Z",
     "start_time": "2020-05-18T23:22:16.921773Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot use cuda :(, though this may help us later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T23:23:17.615665Z",
     "start_time": "2020-05-18T23:23:17.604750Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.device?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # Initialize cuda device\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd : automatic differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, if we want to build neural nets, we need a powerful engine to compute gradients. PyTorch's `autograd` module is specialized for this. \n",
    "\n",
    "`autograd` provides automatic differentiation for tensor operations, hence its name. \n",
    "\n",
    "### Activating gradient operations \n",
    "\n",
    "`torch.Tensor` is the central class of the package. To perform gradient operations efficiently we can activate them setting the `torch.Tensor` attribute `.requires_grad` as `True`. This attribute tracks all of the tensors than need a gradient, and computes it when we call `backward()` which means backpropagation. The gradient for each tensor will be stored in the `.grad` attribute. \n",
    "\n",
    "To stop a tensor from tracking gradient history, we can call `.detach()`. This will save us memory and avoid making unnecesary / incorrect operations.\n",
    "\n",
    "To prevent tracking we can also wrap the code with `torch.no_grad():`. This can be helpful when evaluating a model because the model may have trainable params with `requires_grad = True`, but for which we don't need gradients. (note-to-self: will need an example to wrap my head around this).\n",
    "\n",
    "### Functions \n",
    "\n",
    "There's one more class which is essential to know - the `Function`. `Tensor` and `Function` are connected to build up an **acyclic graph**, that encodes the history of computation. Each tensor has a `.grad_fn` attribute that references a `Function` that has created the `Tensor` (except for `Tensors` created by the user- where the `grad_fn is None`).\n",
    "\n",
    "\n",
    "If we want to compute the derivatives, we need to call `.backward()` on a `Tensor`. If the `Tensor` is not a scaler, we need to specify a `gradient` argument that is a tensor of matching shape, i.e. the tensor with respect to which we are taking the derivative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T23:44:14.257688Z",
     "start_time": "2020-05-18T23:44:14.242241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize tensor, activate gradient operations\n",
    "x = torch.ones(2,2, requires_grad = True)\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T23:44:34.167104Z",
     "start_time": "2020-05-18T23:44:34.158376Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3.],\n",
       "        [3., 3.]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform a tensor operation \n",
    "\n",
    "y = x+2\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because y was created as a result of an operation, it has a `grad_fn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T23:45:04.945767Z",
     "start_time": "2020-05-18T23:45:04.939821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x128c2b210>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T23:45:12.213860Z",
     "start_time": "2020-05-18T23:45:12.207587Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Confirm that is None\n",
    "print(x.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do more operations on y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T23:45:39.732707Z",
     "start_time": "2020-05-18T23:45:39.724837Z"
    }
   },
   "outputs": [],
   "source": [
    "z = y*y*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T23:45:41.487757Z",
     "start_time": "2020-05-18T23:45:41.479595Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[27., 27.],\n",
       "        [27., 27.]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T23:46:00.024697Z",
     "start_time": "2020-05-18T23:45:59.974395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[18., 18.],\n",
       "        [18., 18.]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication \n",
    "y @ y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T23:46:31.612471Z",
     "start_time": "2020-05-18T23:46:31.600651Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(27., grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = z.mean()\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.requires_grad_(...)` changes an existing Tensor's `requires_grad` flag in-place. The input flag defaults to `False` if not given. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T23:47:36.950306Z",
     "start_time": "2020-05-18T23:47:36.941008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2,2) \n",
    "\n",
    "a = ((a*3) / (a-1))\n",
    "\n",
    "print(a.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T23:47:50.460318Z",
     "start_time": "2020-05-18T23:47:50.452080Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "a.requires_grad_(True)\n",
    "\n",
    "print(a.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T23:48:07.665243Z",
     "start_time": "2020-05-18T23:48:07.638289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SumBackward0 object at 0x128c093d0>\n"
     ]
    }
   ],
   "source": [
    "b = (a*a).sum()\n",
    "\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply backprop. Because `out` contains a scalar, `out.backward()`is equivalent to `out.backward(torch.tensor(1.)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T23:49:13.032446Z",
     "start_time": "2020-05-18T23:49:13.017277Z"
    }
   },
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print gradients d(out) / dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T23:49:35.023460Z",
     "start_time": "2020-05-18T23:49:35.013084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T23:49:37.521256Z",
     "start_time": "2020-05-18T23:49:37.511929Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T23:49:40.071840Z",
     "start_time": "2020-05-18T23:49:40.061769Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(27., grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call out the `out` tensor \"o\". We have that \n",
    "\n",
    "\\begin{align}\n",
    "o = \\frac{1}{4} \\sum z_i \\\\[.8em]\n",
    "z_i = 3(x_i + 2)^2\\\\[.89em]\n",
    "z_i\\bigg\\rvert_{x_i = 1} = 27\n",
    "\\end{align}\n",
    "\n",
    "Therefore \n",
    "\n",
    "\\begin{align}\n",
    "\\frac{do}{dx_i} = \\frac{3}{2}(x_i + 2) \\\\[1em]\n",
    "\\frac{do}{dx_i}\\bigg\\rvert_{x_i = 1} = \\frac{9}{2} = 4.5\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have a vector valued function $\\vec{y}$ = $f(\\vec{x})$, then the gradient of $\\vec{y}$ with respect to $\\vec{x}$ is a Jacobian matrix  (size $m n$): \n",
    "\n",
    "\\begin{align}\n",
    "\\frac{d \\vec{y}}{d \\vec{x}} = \n",
    "\\mathbf{J} =\n",
    "\\begin{bmatrix}\n",
    "  \\frac{\\partial y_1}{\\partial x_1} & \n",
    "    \\cdots & \n",
    "    \\frac{\\partial y_1}{\\partial x_n} \\\\[1ex] % <-- 1ex more space between rows of matrix\n",
    "  \\vdots & \n",
    "    \\ddots & \n",
    "    \\vdots \\\\[1ex]\n",
    "  \\frac{\\partial y_m}{\\partial x_1} & \n",
    "   \\cdots& \n",
    "    \\frac{\\partial y_m}{\\partial x_n}\n",
    "\\end{bmatrix}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally speaking, `torch.autograd` is an engine for computing vector-Jacobian products. That is, for any given vector $\\vec{v} = ( v_1, v_2, ..., v_m)^T$, compute the product $\\vec{v}^T \\mathbf {J}$. If $\\vec{v}$ happens to be the gradient of a scalar function $l = g(\\vec{y})$, that is, $\\vec{v} = ( \\frac{\\partial l}{\\partial y_1} \\cdots \\frac{\\partial l}{\\partial y_m}^T$, then by the chain rule, the vector-Jacobian product would be the gradient of $l$ with respect to $\\vec x$: \n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf {J}^T v =\n",
    "    \\begin{bmatrix} \n",
    "        \\frac{\\partial y_1}{\\partial x_1} &\n",
    "        \\cdots &\n",
    "        \\frac{\\partial y_m}{ \\partial x_1} \\\\[1ex]\n",
    "        \\vdots &\n",
    "        \\ddots &\n",
    "        \\vdots \\\\[1ex]\n",
    "        \\frac{ \\partial y_1}{ \\partial x_n} &\n",
    "        \\cdots &\n",
    "        \\frac{ \\partial y_m}{ \\partial x_n}\\\\\n",
    "    \\end{bmatrix}\n",
    "    \\begin{bmatrix}\n",
    "        \\frac{\\partial l}{\\partial y_1}\\\\[1ex]\n",
    "        \\vdots \\\\[1ex]\n",
    "        \\frac{\\partial l}{\\partial y_m}\\\\[1ex]\n",
    "    \\end{bmatrix}\n",
    "    = \n",
    "    \\begin{bmatrix}\n",
    "        \\frac{\\partial l}{\\partial x_1}\\\\[1ex]\n",
    "        \\vdots \\\\[1ex]\n",
    "        \\frac{\\partial l}{\\partial x_n}\\\\[1ex]\n",
    "    \\end{bmatrix}\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that $v^T \\mathbf J$ gives a row vector of size (1 x n), which can be treated as a column vector by taking $\\mathbf {J}^T v$. \n",
    "\n",
    "This characteristic of vector-Jacobian product makes it very convenient to feed external gradients into a model that has a non-scalar output. Now let's take a look at an example of vector-Jacobian product: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T00:30:25.778022Z",
     "start_time": "2020-05-19T00:30:25.772057Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.randn(3,requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T00:30:49.855131Z",
     "start_time": "2020-05-19T00:30:49.850900Z"
    }
   },
   "outputs": [],
   "source": [
    "y = x*2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T00:32:19.291913Z",
     "start_time": "2020-05-19T00:32:19.277988Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.0242)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.data.norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T00:32:25.823106Z",
     "start_time": "2020-05-19T00:32:25.814692Z"
    }
   },
   "outputs": [],
   "source": [
    "# Iterate until Frobenius norm is >= 1000\n",
    "while y.data.norm()< 1000: \n",
    "    y *= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T00:32:29.277178Z",
     "start_time": "2020-05-19T00:32:29.267543Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-699.2209, -828.4683, 1105.5530], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in this case, y is no longer a scalar. `torch.autograd` could not compute the full Jacobian directly, but if we just want the vector-Jacobian product, simply pass the vector to backward as argument: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T00:34:20.357254Z",
     "start_time": "2020-05-19T00:34:20.350161Z"
    }
   },
   "outputs": [],
   "source": [
    "v = torch.tensor([0.1, 1, 0.0001], dtype = torch.float)\n",
    "\n",
    "y.backward(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T00:35:25.244114Z",
     "start_time": "2020-05-19T00:35:25.233124Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-699.2209, -828.4683, 1105.5530], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T00:34:43.539144Z",
     "start_time": "2020-05-19T00:34:43.531103Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also stop autograd from tracking history on Tensors with `.requires_grad=True` either by wrapping the code block in `with torch.no_grad()`  or usign `.detach()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T00:36:45.677721Z",
     "start_time": "2020-05-19T00:36:45.670075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T00:37:03.375802Z",
     "start_time": "2020-05-19T00:37:03.365687Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print((x**2).requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T00:37:18.945601Z",
     "start_time": "2020-05-19T00:37:18.936890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): \n",
    "    print((x**2).requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T00:37:51.823879Z",
     "start_time": "2020-05-19T00:37:51.809919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "\n",
    "y = x.detach()\n",
    "\n",
    "print(x.requires_grad)\n",
    "print(y.requires_grad)\n",
    "\n",
    "# Notice the elegance \n",
    "print(x.eq(y).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural nets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural nets are constructed using the `torch.nn` module. \n",
    "\n",
    "`nn` dpeneds on `autograd` to define models and differentiate them. A `nn.Module` contains layers, and a method `forward(input)` that returns the `output`. \n",
    "\n",
    "Let's look at an example of a conv-net that classifies digits, the famous Yann Le Cunn's Le net. It is a simple feed-forward network. It takes the input, feeds it through several layers, and gives the output. \n",
    "\n",
    "A typical training procedure for a neural network is as follows. \n",
    "\n",
    "* Define the net that has some learnable params (or weights). \n",
    "* Iterate over a dataset of inputs \n",
    "* Process input through the net. \n",
    "* Compute the loss or error metric. \n",
    "* (Back)Propagate the gradients into the network's parameters. \n",
    "* Update the weights, tipically using a simple learning rule `weight (i) = weight (i-1) - learning_rate * gradient` . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define Le Net. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T01:00:48.869555Z",
     "start_time": "2020-05-19T01:00:48.864196Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T01:03:05.931906Z",
     "start_time": "2020-05-19T01:03:05.924922Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `nn.Module.fc` not found.\n"
     ]
    }
   ],
   "source": [
    "nn.Module.fc?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> \"A convolutional layer applies the same (usually small) filter repeatedly at different positions in the layer below it. E.g. if the input layer has dimensions 512 x 512, you could have a conv layer that applies the same 8 x 8 filter (specified by 64 **filter coefficients**), at each point in (e.g.) a 128 x 128 grid overlaid on the input layer. On the other hand, each node in a fully connected layer would learn 512 x 512 weights, one for each of the nodes in the input layer\" : i.e. a convolutional layer allows us to *learn a filter*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T01:14:47.699675Z",
     "start_time": "2020-05-19T01:14:47.686470Z"
    }
   },
   "outputs": [],
   "source": [
    "class LeNet(nn.Module): \n",
    "    \n",
    "    def __init__(self): \n",
    "        super(LeNet, self).__init__()\n",
    "        \n",
    "        # 1 input image channel, 6 output channels, 3x3 square conv kernel \n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        \n",
    "        # an affine operation y = Wx + b \n",
    "        # fc = fully connected \n",
    "        self.fc1 = nn.Linear(16*6*6, 120) # 6*6 from image dimension \n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10) # Final output = 10 (digits)\n",
    "        \n",
    "    def forward(self, x): \n",
    "        \n",
    "        # Max pooling over a (2,2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        \n",
    "        # If the size is a square you can only specify a single number \n",
    "        \n",
    "        x =  F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x \n",
    "    \n",
    "    def num_flat_features(self, x): \n",
    "        \n",
    "        size = x.size()[1:] # all dimensions except the batch dim\n",
    "        num_features = 1\n",
    "        \n",
    "        for s in size: \n",
    "            num_features *=s\n",
    "            \n",
    "        return num_features \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T01:16:54.714077Z",
     "start_time": "2020-05-19T01:16:54.702469Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = LeNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, all what's left is to define a `forward` function and the `backward` function. You can use any of the Tensor operations in the forward function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T01:18:54.057752Z",
     "start_time": "2020-05-19T01:18:54.049049Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size()) # conv1's weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a random 32x32 input. Note: expected input sizze of LeNet is 32x32. To use this net on the MNIST dataset resize the images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T01:24:16.398082Z",
     "start_time": "2020-05-19T01:24:16.388274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0274, -0.0543,  0.0122, -0.0415, -0.1333,  0.0223, -0.1412,  0.1200,\n",
      "         -0.0212,  0.0013]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input_ = torch.randn(1, 1, 32, 32)\n",
    "out = net(input_)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zero the gradient buffers of all parameters and backprops with random gradients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T01:20:44.164004Z",
     "start_time": "2020-05-19T01:20:44.148168Z"
    }
   },
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "\n",
    "out.backward(torch.randn(1,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: `torch.nn` only supports mini-batches. The entire `torch.nn` package only supports inputs that are a mini-batch of samples, and not a single sample.\n",
    "\n",
    "For example, nn.Conv2d will take in a 4D Tensor of nSamples x nChannels x Height x Width.\n",
    "\n",
    "If you have a single sample, just use input.unsqueeze(0) to add a fake batch dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding further, let’s recap all the classes you’ve seen so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recap \n",
    "\n",
    "* `torch.Tensor`: A multi-dimensional array with support for autograd operations like `backward`. Also holds the gradient w.r.t. the tensor. \n",
    "\n",
    "* `nn.Module` : Neural network module. Convenient way of encapsulating parameters, with helpers for moving them to GPU, exporting, loading, etc. \n",
    "\n",
    "* `nn.Parameter` : A kind of Tensor, that is *automatically* registered as a paameter when assigned as an attribute to a *Module*. \n",
    "\n",
    "* `autograd.Function`: Implements forward and backward definitions of an autograd operation. Every Tensor operation creates at least a single `Function`node that connects to functions that created a `Tensor` and *encodes* its history. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A loss function takes the (output, target) pair of inputs, and computes a value that estimates how far away the output is from the target. You can look at a myriad of different loss functions here at the [nn module docs](https://pytorch.org/docs/stable/nn.html), or program your own ! \n",
    "\n",
    "There are several different **loss functions** under the `nn` package. A simple loss is: `nn.MSELoss` which computes the mean-squared error between the input and the target. \n",
    "\n",
    "For example: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T01:31:08.271219Z",
     "start_time": "2020-05-19T01:31:08.260195Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7131, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "output = net(input_)\n",
    "target = torch.randn(10) # a dummy target for example\n",
    "\n",
    "target = target.view(1, -1) # to have same shape as output\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(output, target)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T01:31:44.585434Z",
     "start_time": "2020-05-19T01:31:44.576101Z"
    }
   },
   "source": [
    "Now, if you follow `loss` in the backward direction, using its `.grad_fn` attribute, you will see a graph of computations that looks like this: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`input -> conv2d -> relu -> maxplool2d -> conv2d -> relu -> maxpool2d\n",
    "       -> view(flatten) -> linear -> relu -> linear \n",
    "       -> MSELoss \n",
    "       -> loss`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where `relu` is the [rectified linear unit](https://www.kaggle.com/dansbecker/rectified-linear-units-relu-in-deep-learning) activation function. \n",
    "\n",
    "When we call `loss.backward()`, the whole graph is differentiated w.r.t. the loss, and all Tensors in the graph that have a `requires_grad = True` will have their `.grad` Tensor accumulated with the gradient. \n",
    "\n",
    "For illustration, let us follow a few steps backward: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T01:36:10.558022Z",
     "start_time": "2020-05-19T01:36:10.548880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x127aeb750>\n",
      "<AddmmBackward object at 0x127abb210>\n",
      "<AccumulateGrad object at 0x128c708d0>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)\n",
    "\n",
    "print(loss.grad_fn.next_functions[0][0]) ## Linear\n",
    "\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0]) # ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To backprop the error all we have to do is to `loss.backward()`. You need to clear the existing gradients though, else gradients will be accumulated! \n",
    "\n",
    "Now we shall call `loss.backward()`, and have a look at conv1's bias gradients before and after the backward. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T01:38:45.741940Z",
     "start_time": "2020-05-19T01:38:45.733203Z"
    }
   },
   "outputs": [],
   "source": [
    "net.zero_grad() # zeroes out the gradient buffers of all params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T01:38:55.170763Z",
     "start_time": "2020-05-19T01:38:55.153333Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "conv1.bias.grad after backward\n",
      "tensor([-0.0261,  0.0166,  0.0031,  0.0163,  0.0003,  0.0060])\n"
     ]
    }
   ],
   "source": [
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only thing left to do is to use a learning rule to update the weights torch-style. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T01:50:19.949264Z",
     "start_time": "2020-05-19T01:50:19.945712Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T01:51:23.098670Z",
     "start_time": "2020-05-19T01:51:23.075094Z"
    }
   },
   "outputs": [],
   "source": [
    "# create optimizer \n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr = 1e-3)\n",
    "\n",
    "# Do training loop \n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "output = net(input_)\n",
    "\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More on optimizers\n",
    "\n",
    "Another thing to keep in mind is that the default optimizer is Adam (`optim.Adam`), but there are Stochastic Gradient descent (`optim.SGD`) and Adagrad (`optim.Adafrad`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is it. We've seen how to define nets, compute loss and update the weights. Let's load a dataset and test our architecture. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About datasets \n",
    "\n",
    "Remember that to input data into a torch neural net, we need to convert the input to `torch.Tensor`s. Therefore, we can use several other libraries to get the data into a numpy format and then transform it using `from_numpy` method. \n",
    "\n",
    "For computer vision, torch has a package called `torchvision`, that has data loaders for common datasets such as Imagenet, CIFAR10, MNIST, etc. It also has data transformers for images like `torch.utils.data.DataLoader`. This avoids making boilerplate code. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training an image classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do the following steps in order: \n",
    "\n",
    "1. Load and normalize CIFAR10 training and test datasets using `torchvision`\n",
    "2. Define a ConvNet \n",
    "3. Define a loss function. \n",
    "4. Train the net. \n",
    "5. Test the net. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and noramlizing CIFAR10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T01:57:43.999720Z",
     "start_time": "2020-05-19T01:57:43.382278Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision \n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of `torchvision.datasets` are PILImage images of range [0,1]. We transform them to tensors of normalized range [-1,1]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T02:00:31.693304Z",
     "start_time": "2020-05-19T01:59:52.557671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c05abdaa9db6418d9136bbeaea1c321c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data/\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (.5, .5, .5))\n",
    "    ]\n",
    ")\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root = './data/', \n",
    "    train = True, \n",
    "    download = True, \n",
    "    transform = transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T02:00:45.444275Z",
     "start_time": "2020-05-19T02:00:45.439114Z"
    }
   },
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, \n",
    "    batch_size = 4, \n",
    "    shuffle = True, \n",
    "    num_workers = 2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T02:02:24.716038Z",
     "start_time": "2020-05-19T02:02:23.538063Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root = './data',\n",
    "    train = False, \n",
    "    download = True, \n",
    "    transform = transform \n",
    ")\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, \n",
    "    batch_size = 4, \n",
    "    shuffle = False, \n",
    "    num_workers = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T02:03:07.092542Z",
     "start_time": "2020-05-19T02:03:07.088051Z"
    }
   },
   "outputs": [],
   "source": [
    "classes = (\n",
    "    'plane', \n",
    "    'car', \n",
    "    'bird', \n",
    "    'cat', \n",
    "    'deer',\n",
    "    'dog', \n",
    "    'frog', \n",
    "    'horse', \n",
    "    'ship', \n",
    "    'truck'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T02:03:22.567874Z",
     "start_time": "2020-05-19T02:03:22.117460Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T02:23:48.338922Z",
     "start_time": "2020-05-19T02:23:48.329635Z"
    }
   },
   "outputs": [],
   "source": [
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T02:23:51.239599Z",
     "start_time": "2020-05-19T02:23:51.229743Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 3, 9, 4])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T02:23:55.547798Z",
     "start_time": "2020-05-19T02:23:55.538869Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 32, 32])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T02:05:40.393164Z",
     "start_time": "2020-05-19T02:05:39.741240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plane ship deer  dog\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(img): \n",
    "    img = img/2 + 0.5 # unnormalize \n",
    "    \n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "    \n",
    "# Get some random training images    \n",
    "dataiter = iter(trainloader)\n",
    "\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images \n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "print(''.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a conv net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the same neural net but modify it to take 3-channel images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T02:15:42.661257Z",
     "start_time": "2020-05-19T02:15:42.647674Z"
    }
   },
   "outputs": [],
   "source": [
    "class laNets(nn.Module): \n",
    "    def __init__(self): \n",
    "        super(laNets, self).__init__()\n",
    "        \n",
    "        # Input channels, output channels, size of conv filter 5x5\n",
    "        self.conv1 = nn.Conv2d(3,6,5)\n",
    "        \n",
    "        # Subsample by max operator \n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        # Output channels x conv filter size\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x): \n",
    "        \n",
    "        # subsample Conv layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        x = x.view(-1, 16*5*5) # flatten for fully connected layer \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T02:15:43.400648Z",
     "start_time": "2020-05-19T02:15:43.390052Z"
    }
   },
   "outputs": [],
   "source": [
    "# LeNet chilango-style\n",
    "net = laNets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define loss function and optimizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T02:17:16.445549Z",
     "start_time": "2020-05-19T02:17:16.438987Z"
    }
   },
   "outputs": [],
   "source": [
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the net "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T02:32:06.787469Z",
     "start_time": "2020-05-19T02:28:22.302024Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.737\n",
      "[1,  4000] loss: 1.568\n",
      "[1,  6000] loss: 1.500\n",
      "[1,  8000] loss: 1.430\n",
      "[1, 10000] loss: 1.371\n",
      "[1, 12000] loss: 1.355\n",
      "[2,  2000] loss: 1.273\n",
      "[2,  4000] loss: 1.272\n",
      "[2,  6000] loss: 1.268\n",
      "[2,  8000] loss: 1.274\n",
      "[2, 10000] loss: 1.249\n",
      "[2, 12000] loss: 1.211\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "for epoch in np.arange(2): # Loop over dataset multiple times \n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for ix, data in enumerate(trainloader):\n",
    "        \n",
    "        # Get the inputs; data is a list of [inputs, labels]\n",
    "        \n",
    "        inputs, labels = data\n",
    "        \n",
    "        #print(labels)\n",
    "        \n",
    "        # zero the param gradients \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        #print(outputs)\n",
    "        \n",
    "        # Compute cross entropy \n",
    "        loss = cross_entropy(outputs, labels)\n",
    "        \n",
    "        loss.backward() #backprop\n",
    "        \n",
    "        optimizer.step() # Update weights \n",
    "        \n",
    "        # print stats \n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if ix % 2000 == 1999: # print every 2000 mini-batches\n",
    "            \n",
    "            # Slightly awkward print statement \n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, ix+1, running_loss / 2000))\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            \n",
    "print('Finished training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that indeed, the cross entropy steadily decreased during the training procedure. \n",
    "\n",
    "We can save our model with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = './cifar_net.pth'\n",
    "# torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the network on the test data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have trained the network for 2 passes over the training set. But we need to check if the net has learnt anything at all. \n",
    "\n",
    "Let's check by predicting the outputs, and checking it against the ground truth. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T02:32:33.167527Z",
     "start_time": "2020-05-19T02:32:33.155694Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('plane',\n",
       " 'car',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T02:32:50.307045Z",
     "start_time": "2020-05-19T02:32:49.867029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth :    cat   ship   ship  plane \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataiter = iter(testloader)\n",
    "\n",
    "images, labels = test_dataiter.next()\n",
    "\n",
    "# print images \n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# 4 is the batch size \n",
    "print('Ground truth : ', ' '.join('%5s '% classes[labels[j]] for j in range(4) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how the network performs on the whole dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T02:33:51.298320Z",
     "start_time": "2020-05-19T02:33:45.001488Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 54 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks way better than chance, which is 10% accuracy (randomly picking a class out of 10 classes). Seems like the network learnt something."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm, what are the classes that performed well, and the classes that did not perform well:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T02:34:25.734955Z",
     "start_time": "2020-05-19T02:34:18.820263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 49 %\n",
      "Accuracy of   car : 73 %\n",
      "Accuracy of  bird : 48 %\n",
      "Accuracy of   cat : 63 %\n",
      "Accuracy of  deer : 27 %\n",
      "Accuracy of   dog : 30 %\n",
      "Accuracy of  frog : 57 %\n",
      "Accuracy of horse : 54 %\n",
      "Accuracy of  ship : 77 %\n",
      "Accuracy of truck : 61 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the network gets confused by cats, deer, and dogs. An easy fix is to let the network train for more epochs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training on a GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just how we transfer a Tensor onto a GPU, we can transfer the whole neural net onto the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T02:35:46.756529Z",
     "start_time": "2020-05-19T02:35:46.746766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all we have to do is pass every object with a  `to(device)` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.to(device)\n",
    "\n",
    "# inputs, labels = data[0].to(device), data[1].to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Massive speedups are achieved when we start scaling up to larger networks. We can also go parallel ! Check the [parallel tutorial](https://pytorch.org/tutorials/beginner/blitz/data_parallel_tutorial.html) for getting all of that GPU juice ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
