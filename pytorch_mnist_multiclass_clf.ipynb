{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic PyTorch tutorial\n",
    "\n",
    "This tutorial will serve as a simple introduction to PyTorch. It will cover the following: \n",
    "1. Declare and initialize a neural network (Multi-layer perceptron)\n",
    "2. Load train/test data (MNIST)\n",
    "3. Train a neural network to perform the task\n",
    "4. Evaluate test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T22:49:55.787205Z",
     "start_time": "2020-05-18T22:49:51.988583Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manoloflores/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import copy, random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading train/test data (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [00:01, 9404837.34it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/MNIST/raw/train-images-idx3-ubyte.gz to MNIST/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32768it [00:00, 118734.58it/s]           \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/MNIST/raw/train-labels-idx1-ubyte.gz to MNIST/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1654784it [00:00, 2362622.66it/s]                           \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8192it [00:00, 40343.20it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainset =   torchvision.datasets.MNIST('MNIST/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.MNIST('MNIST/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader( testset, batch_size=4, shuffle=True)\n",
    "\n",
    "classes = ('0','1', '2', '3', '4','5', '6', '7', '8', '9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declaring a neural network (Multi-layer perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP DEFINITION\n",
    "\n",
    "### This network has 4 layers: \n",
    "### Input [784 x 1] --> Hidden-1 [300 x 1] --> Hidden-2 [100 x 1] --> Output [10 x 1]\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLP_MNIST(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MLP_MNIST, self).__init__()\n",
    "        random_seed = 1;\n",
    "        torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(784,300),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(300,100),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(100,10)\n",
    "            )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = self.fc(x);\n",
    "        return x\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the weights and biases of the neural network. This is a Xavier initialization; \n",
    "# Optimal initialization of NN's is an entire field in itself :D \n",
    "\n",
    "def initialize_network(net):\n",
    "\n",
    "    random_seed = 1;\n",
    "    torch.manual_seed(random_seed)\n",
    "    for m in net.modules():\n",
    "        torch.manual_seed(random_seed)\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight);\n",
    "            nn.init.uniform_(m.bias);\n",
    "    \n",
    "    return net\n",
    "    '''\n",
    "    for name, param in autoenc_ch.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(name, param.data)\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to evaluate the test accuracy of the network on test-data from MNIST\n",
    "\n",
    "def generalization_acc(net_mod):\n",
    "\n",
    "    correct = 0;\n",
    "    total = 0\n",
    "    batch_size = 4;\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images = images.view(batch_size, -1)\n",
    "            outputs = net_mod(images);\n",
    "            _, predicted = torch.max(outputs.data,1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    #print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "    return (100 * correct / total);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to evaluate the train-accuracy of the network on the train-data from MNIST\n",
    "## (NOTE): There may be cases where the network has a very high train-accuracy but low test-accuracy --> commonly called overfitting\n",
    "\n",
    "def train_accuracyMNIST(net_mod):\n",
    "\n",
    "    correct = 0;\n",
    "    total = 0\n",
    "    batch_size = 4;\n",
    "    with torch.no_grad():\n",
    "        for data in trainloader:\n",
    "            images, labels = data\n",
    "            images = images.view(batch_size, -1)\n",
    "            outputs = net_mod(images);\n",
    "            _, predicted = torch.max(outputs.data,1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 60000 train images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "    return (100 * correct / total);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining a Loss function for the neural network. \n",
    "# here, we use the cross-entropy loss. One can use L2 loss (any loss that is appropriate for the task at hand)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss();\n",
    "num_epochs = 2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function for training neural network \n",
    "\n",
    "def trainNetwork_MNIST(net, wtsDict, num_epochs=2):\n",
    "\n",
    "    ## net: corresponds to the neural network that requires training\n",
    "    ## wtsDict: dictionary of weights, if you want to store the weights of intermediate networks while training (not reqd for conventional purposes)\n",
    "    ## num_epochs: number of epochs networks are to be trained for. One epoch is training the network on all train-datapoints in the batch\n",
    "    \n",
    "    \n",
    "    #storeWts_manifold2(net, wtsDict)\n",
    "    \n",
    "    ## Choosing an optimizer. Here, we choose Stochastic gradient descent (SGD) with learning rate=0.001 and momentum = 0.9\n",
    "    optimizer = optim.SGD(net.parameters(),lr=0.001, momentum=0.9)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        running_loss = 0.0;\n",
    "        batch_size = 4;\n",
    "\n",
    "        ctr_run = 0;\n",
    "        for i in range(0, 60000, batch_size):\n",
    "                \n",
    "            image_input = torch.empty(batch_size,784)\n",
    "            labels = torch.empty(batch_size);\n",
    "\n",
    "            for j in range(batch_size):\n",
    "                img, label = trainset[i+j]\n",
    "                img = img[0,:,:];\n",
    "                img = img.view(1,784)\n",
    "        \n",
    "                image_input[j,:] = img;\n",
    "                labels[j] = label;\n",
    "\n",
    "            output = net(image_input);\n",
    "            loss = criterion(output, labels.long());\n",
    "\n",
    "            # =====================backward==================\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            #plot_grad_flow(autoenc_ch.named_parameters)\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if ctr_run % 2000 == 1999: # print every 8000 samples\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, ctr_run + 1, running_loss / 2000))\n",
    "                running_loss = 0.0;\n",
    "                #storeWts_manifold2(net, wtsDict); \n",
    "                #calcLoss_network.append(calculateLoss_network(net))\n",
    "                \n",
    "            ctr_run += 1;\n",
    "\n",
    "        acc = train_accuracyMNIST(net);\n",
    "        print(\"within func\")\n",
    "        \n",
    "        \n",
    "        ## I terminate training when accuracy reaches 98%; \n",
    "        ## One could train for a fixed number of epochs or until the network reaches a particular accuracy.\n",
    "        if num_epochs != 2:\n",
    "            # Evaluate if train accuracy is greater than 98%\n",
    "            if acc>98:\n",
    "                #storeWts_manifold2(net, wtsDict)\n",
    "                return (epoch+1, acc)\n",
    "        \n",
    "    return (epoch+1, acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calling all the functions [to train the net]\n",
    "\n",
    "net_MNIST = MLP_MNIST();\n",
    "\n",
    "wtsDictionary_landscape = {};\n",
    "ctr = 1;\n",
    "for n,p in net_MNIST.named_parameters():\n",
    "        \n",
    "    temp = list(p.view(1,-1).size());\n",
    "    wtsDictionary_landscape[ctr] = np.array([]).reshape(0,temp[1]);\n",
    "    ctr += 1\n",
    "    \n",
    "net_train = copy.deepcopy(net_MNIST);\n",
    "[returnTime, acc] = trainNetwork_MNIST(net_train, wtsDictionary_landscape, 5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
